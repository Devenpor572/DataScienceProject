{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 5665 Project\n",
    "## Tools\n",
    "These tools are used by each code chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_path():\n",
    "    import os\n",
    "    import inspect\n",
    "    OUTPUT_DIR = 'output'\n",
    "    caller_name = inspect.stack()[1][3]\n",
    "    output_path = os.path.join(OUTPUT_DIR, caller_name)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path) \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 1 - Cleaning and Augmenting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    def read_data():\n",
    "        df_movies = pd.read_csv('output/merged.csv')\n",
    "        df_movie_stats = pd.read_csv('output/rectified/the_numbers_movie_stats.csv')\n",
    "        df_stat_infos = pd.read_csv('output/rectified/the_numbers_stat_infos.csv')\n",
    "        return df_movies, df_movie_stats, df_stat_infos\n",
    "\n",
    "    def clean_movie_data(df_movies):\n",
    "        df_movies.dropna(subset=['imdb_ids'], inplace=True)\n",
    "        df_movies.drop(columns=['Unnamed: 0', 'imdb_id'], inplace=True)\n",
    "        df_movies.rename(columns={'imdb_ids': 'imdb_id', 'imdb': 'imdb_score', 'running-time': 'running_time'},\n",
    "                         inplace=True)\n",
    "        # Only interested in movies with a budget of 10000000 or more\n",
    "        print('{} total movies'.format(df_movies.shape[0]))\n",
    "        df_movies = df_movies[df_movies['production_budget'] >= 10000000]\n",
    "        print('{} movies with budget 10,000,000 or more'.format(df_movies.shape[0]))\n",
    "        # Only interested in movies that have finalized data (not 2019)\n",
    "        df_movies = df_movies[df_movies['year'] < 2019]\n",
    "        print('{} movies with budget 10,000,000 or more and before 2019'.format(df_movies.shape[0]))\n",
    "        # Only interested in movies in the last 50 years\n",
    "        df_movies = df_movies[df_movies['year'] >= 1970]\n",
    "        print('{} movies with budget 10,000,000 or more and before 2019 and later than 1970'.format(df_movies.shape[0]))\n",
    "        return df_movies\n",
    "        \n",
    "    def clean_movie_stats(df_movie_stats):\n",
    "        df_movie_stats.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    def normalize(df, column):\n",
    "        mean = df[column].mean()\n",
    "        std_dev = df[column].std()\n",
    "        diff = df[column] - mean\n",
    "        norm = diff / std_dev\n",
    "        df['{}_norm'.format(column)] = norm\n",
    "        return mean, std_dev\n",
    "\n",
    "    def augment_movie_data(df_movies):\n",
    "        df_movies['profit'] = df_movies['worldwide_gross'] - df_movies['production_budget']\n",
    "        df_movies['profit_margin'] = (df_movies['worldwide_gross'] - df_movies['production_budget']) / df_movies['worldwide_gross']\n",
    "        df_movies['rate_of_return'] = (df_movies['worldwide_gross'] / df_movies['production_budget']).round(4)\n",
    "        normalize(df_movies, 'metascore')\n",
    "        normalize(df_movies, 'imdb_score')\n",
    "        df_movies['rate_of_return_log'] = np.log(df_movies['rate_of_return'])\n",
    "        df_movies.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        df_movies.dropna(subset=['rate_of_return_log'], inplace=True)\n",
    "        mean_ror, std_dev_ror = normalize(df_movies, 'rate_of_return_log')\n",
    "        df_movies['class_performance'] = pd.cut(df_movies['rate_of_return_log_norm'], [-np.inf, mean_ror, np.inf], labels=['BELOW_AVG', 'ABOVE_AVG'])\n",
    "        df_movies['class_success'] = pd.cut(df_movies['rate_of_return_log'], [-np.inf, 0, np.inf], labels=['FAIL', 'SUCCESS'])\n",
    "        display(df_movies)\n",
    "        df_movies['production_budget_log'] = np.log(df_movies['production_budget'])\n",
    "        df_movies.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        normalize(df_movies, 'production_budget_log')\n",
    "        df_movies['domestic_gross_log'] = np.log(df_movies['domestic_gross'])\n",
    "        df_movies.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        normalize(df_movies, 'domestic_gross_log')\n",
    "        df_movies['worldwide_gross_log'] = np.log(df_movies['worldwide_gross'])\n",
    "        df_movies.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        normalize(df_movies, 'worldwide_gross_log')\n",
    "        df_movies['votes_log'] = np.log(df_movies['votes'])\n",
    "        df_movies.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        normalize(df_movies, 'votes_log')\n",
    "\n",
    "    def get_movie_info():\n",
    "        df_movies, df_movie_stats, df_stat_infos = read_data()\n",
    "        df_movies = clean_movie_data(df_movies)\n",
    "        clean_movie_stats(df_movie_stats)\n",
    "        augment_movie_data(df_movies)\n",
    "        df_movies.sort_values(by='year', ascending=False, inplace=True)\n",
    "        display(df_movies)\n",
    "        display(df_movie_stats)\n",
    "        display(df_stat_infos)\n",
    "        return df_movies, df_movie_stats, df_stat_infos\n",
    "\n",
    "    return get_movie_info()\n",
    "\n",
    "\n",
    "# Output\n",
    "# df_movies - List of movie titles and various stats\n",
    "# df_movie_stats - A mapping of movies to stat info indexes\n",
    "# df_stat_infos - The info for each stat\n",
    "df_movies, df_movie_stats, df_stat_infos = function1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 2 - Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2(df_movies):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import os\n",
    "    OUTPUT_PATH = get_output_path()\n",
    "    \n",
    "    def plot_histogram(df):\n",
    "        temp_df = df.drop(columns=['imdb_id'])\n",
    "        temp_df = temp_df[np.isfinite(temp_df['profit_margin'])]\n",
    "        temp_df.hist(color='DarkBlue',figsize=(12,10), xrot=-30, bins=20)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_PATH, 'histograms.png'))\n",
    "        plt.show()\n",
    "        \n",
    "    plot_histogram(df_movies)\n",
    "\n",
    "# Input\n",
    "# df_movies - List of movie titles and various stats\n",
    "function2(df_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 3 - Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function3(df_movies):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    OUTPUT_PATH = get_output_path()\n",
    "    \n",
    "    pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "    description_df = df_movies.describe()\n",
    "    description_df.to_csv(os.path.join(OUTPUT_PATH, 'description.csv'))\n",
    "    display(description_df)\n",
    "\n",
    "# Input\n",
    "# df_movies - List of movie titles and various stats\n",
    "function3(df_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 4 - Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function4(df_movies):\n",
    "    # https://github.com/drazenz/heatmap/blob/master/heatmap.py\n",
    "    # https://github.com/drazenz/heatmap/blob/master/Circle%20heatmap.ipynb\n",
    "    from matplotlib import pyplot as plt\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import os\n",
    "    OUTPUT_PATH = get_output_path()\n",
    "\n",
    "\n",
    "    def heatmap(x, y, **kwargs):\n",
    "        if 'color' in kwargs:\n",
    "            color = kwargs['color']\n",
    "        else:\n",
    "            color = [1]*len(x)\n",
    "\n",
    "        if 'palette' in kwargs:\n",
    "            palette = kwargs['palette']\n",
    "            n_colors = len(palette)\n",
    "        else:\n",
    "            n_colors = 256 # Use 256 colors for the diverging color palette\n",
    "            palette = sns.color_palette(\"Blues\", n_colors) \n",
    "\n",
    "        if 'color_range' in kwargs:\n",
    "            color_min, color_max = kwargs['color_range']\n",
    "        else:\n",
    "            color_min, color_max = min(color), max(color) # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n",
    "\n",
    "        def value_to_color(val):\n",
    "            if color_min == color_max:\n",
    "                return palette[-1]\n",
    "            else:\n",
    "                val_position = float((val - color_min)) / (color_max - color_min) # position of value in the input range, relative to the length of the input range\n",
    "                val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "                ind = int(val_position * (n_colors - 1)) # target index in the color palette\n",
    "                return palette[ind]\n",
    "\n",
    "        if 'size' in kwargs:\n",
    "            size = kwargs['size']\n",
    "        else:\n",
    "            size = [1]*len(x)\n",
    "\n",
    "        if 'size_range' in kwargs:\n",
    "            size_min, size_max = kwargs['size_range'][0], kwargs['size_range'][1]\n",
    "        else:\n",
    "            size_min, size_max = min(size), max(size)\n",
    "\n",
    "        size_scale = kwargs.get('size_scale', 500)\n",
    "\n",
    "        def value_to_size(val):\n",
    "            if size_min == size_max:\n",
    "                return 1 * size_scale\n",
    "            else:\n",
    "                val_position = (val - size_min) * 0.99 / (size_max - size_min) + 0.01 # position of value in the input range, relative to the length of the input range\n",
    "                val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "                return val_position * size_scale\n",
    "        if 'x_order' in kwargs: \n",
    "            x_names = [t for t in kwargs['x_order']]\n",
    "        else:\n",
    "            x_names = [t for t in sorted(set([v for v in x]))]\n",
    "        x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n",
    "\n",
    "        if 'y_order' in kwargs: \n",
    "            y_names = [t for t in kwargs['y_order']]\n",
    "        else:\n",
    "            y_names = [t for t in sorted(set([v for v in y]))]\n",
    "        y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n",
    "\n",
    "        plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) # Setup a 1x10 grid\n",
    "        ax = plt.subplot(plot_grid[:,:-1]) # Use the left 14/15ths of the grid for the main plot\n",
    "\n",
    "        marker = kwargs.get('marker', 's')\n",
    "\n",
    "        kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in [\n",
    "             'color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', 'y_order'\n",
    "        ]}\n",
    "\n",
    "        ax.scatter(\n",
    "            x=[x_to_num[v] for v in x],\n",
    "            y=[y_to_num[v] for v in y],\n",
    "            marker=marker,\n",
    "            s=[value_to_size(v) for v in size], \n",
    "            c=[value_to_color(v) for v in color],\n",
    "            **kwargs_pass_on\n",
    "        )\n",
    "        ax.set_xticks([v for k,v in x_to_num.items()])\n",
    "        ax.set_xticklabels([k for k in x_to_num], rotation=45, horizontalalignment='right')\n",
    "        ax.set_yticks([v for k,v in y_to_num.items()])\n",
    "        ax.set_yticklabels([k for k in y_to_num])\n",
    "\n",
    "        ax.grid(False, 'major')\n",
    "        ax.grid(True, 'minor')\n",
    "        ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n",
    "        ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n",
    "\n",
    "        ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
    "        ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
    "        ax.set_facecolor('#F1F1F1')\n",
    "\n",
    "        # Add color legend on the right side of the plot\n",
    "        if color_min < color_max:\n",
    "            ax = plt.subplot(plot_grid[:,-1]) # Use the rightmost column of the plot\n",
    "\n",
    "            col_x = [0]*len(palette) # Fixed x coordinate for the bars\n",
    "            bar_y=np.linspace(color_min, color_max, n_colors) # y coordinates for each of the n_colors bars\n",
    "\n",
    "            bar_height = bar_y[1] - bar_y[0]\n",
    "            ax.barh(\n",
    "                y=bar_y,\n",
    "                width=[5]*len(palette), # Make bars 5 units wide\n",
    "                left=col_x, # Make bars start at 0\n",
    "                height=bar_height,\n",
    "                color=palette,\n",
    "                linewidth=0\n",
    "            )\n",
    "            ax.set_xlim(1, 2) # Bars are going from 0 to 5, so lets crop the plot somewhere in the middle\n",
    "            ax.grid(False) # Hide grid\n",
    "            ax.set_facecolor('white') # Make background white\n",
    "            ax.set_xticks([]) # Remove horizontal ticks\n",
    "            ax.set_yticks(np.linspace(min(bar_y), max(bar_y), 3)) # Show vertical ticks for min, middle and max\n",
    "            ax.yaxis.tick_right() # Show vertical ticks on the right \n",
    "\n",
    "\n",
    "    def corrplot(data, size_scale=500, marker='s'):\n",
    "        corr = pd.melt(data.reset_index(), id_vars='index')\n",
    "        corr.columns = ['x', 'y', 'value']\n",
    "        heatmap(\n",
    "            corr['x'], corr['y'],\n",
    "            color=corr['value'], color_range=[-1, 1],\n",
    "            palette=sns.diverging_palette(20, 220, n=256),\n",
    "            size=corr['value'].abs(), size_range=[0,1],\n",
    "            marker=marker,\n",
    "            x_order=data.columns,\n",
    "            y_order=data.columns[::-1],\n",
    "            size_scale=size_scale\n",
    "        )\n",
    "        \n",
    "    columns = ['year','imdb_score','metascore','votes','votes_log','running_time','production_budget_log','domestic_gross_log','worldwide_gross_log','profit','rate_of_return_log']\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    corrplot(df_movies[columns].corr().replace(np.nan, 0), size_scale=500)\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'correlation.png'), bbox_inches='tight')\n",
    "\n",
    "# Input\n",
    "# df_movies - List of movie titles and various stats\n",
    "function4(df_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 5 - Plot Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function5(df_movies):\n",
    "    from matplotlib import pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    import os\n",
    "    OUTPUT_PATH = get_output_path()\n",
    "    \n",
    "    def plot_regression_line(x_col, y_col, data):\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        ax = sns.regplot(x=x_col, y=y_col, data=data)\n",
    "        plt.savefig(os.path.join(OUTPUT_PATH, 'correlation_{}_{}.png'.format(x_col, y_col)))\n",
    "        plt.show()\n",
    "    \n",
    "    columns = ['year','imdb_score','metascore','votes_log','running_time','production_budget_log','domestic_gross_log','worldwide_gross_log','profit','rate_of_return_log']\n",
    "    \n",
    "    for i in range(len(columns)):\n",
    "        for j in range(0, i):\n",
    "            plot_regression_line(columns[i], columns[j], df_movies)\n",
    "\n",
    "# Input\n",
    "# df_movies - List of movie titles and various stats\n",
    "function5(df_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 6 - Linear Regression Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function6(df_movies):\n",
    "    from collections import namedtuple\n",
    "    from itertools import chain, combinations\n",
    "    from matplotlib import pyplot as plt\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import KFold\n",
    "    import statsmodels.formula.api as smf\n",
    "    OUTPUT_PATH = get_output_path()\n",
    "    \n",
    "    def make_formula_str(x_cols, y_col):\n",
    "        formulaString = '{} ~ {}'.format(y_col, x_cols[0])\n",
    "        for col in x_cols[1:]:\n",
    "            formulaString += ' + {}'.format(col)\n",
    "        #print(formulaString)\n",
    "        return formulaString\n",
    "    \n",
    "    def calculate_r_squared(data, x_cols, y_col):\n",
    "        data = data.sample(frac=1)\n",
    "        X = data[x_cols].values\n",
    "        y = data[y_col].values\n",
    "        formString = make_formula_str(x_cols, y_col)\n",
    "\n",
    "        lm = LinearRegression()\n",
    "\n",
    "        # 8-fold cross validation\n",
    "        kf = KFold(n_splits=8)\n",
    "        kf.get_n_splits(X)\n",
    "        scoresSK = list()\n",
    "        scores_St = list()\n",
    "\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            #using SK Learn\n",
    "            fit = lm.fit(X_train, y_train)\n",
    "            scoresSK.append(fit.score(X_test, y_test))\n",
    "\n",
    "            #using stats model\n",
    "            fittedModel = smf.ols(formula=formString, data=data).fit()\n",
    "            scores_St.append(fittedModel.rsquared)\n",
    "\n",
    "        return  np.mean(scoresSK), np.std(scoresSK)\n",
    "    \n",
    "    def powerset(iterable):\n",
    "        # powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\n",
    "        s = list(iterable)\n",
    "        return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "    \n",
    "    x_cols = ['year','imdb_score','metascore','votes_log','running_time','production_budget_log']\n",
    "    y_cols = ['domestic_gross_log','worldwide_gross_log','profit','rate_of_return_log']\n",
    "    Result = namedtuple('Result', ['x_cols', 'y_col', 'mean_score', 'std_dev_score'])\n",
    "    results = list()\n",
    "    i = 1\n",
    "    for y_col in y_cols:\n",
    "        for x_cols_subset in powerset(x_cols):\n",
    "            x_cols_subset = list(x_cols_subset)\n",
    "            if len(x_cols_subset) > 0:\n",
    "                df_movies_dropna = df_movies[[y_col] + x_cols_subset].dropna()\n",
    "                mean_score, std_dev_score = calculate_r_squared(df_movies_dropna, x_cols_subset, y_col)\n",
    "                results.append(dict(Result(','.join(x_cols_subset), y_col, mean_score, std_dev_score)._asdict()))\n",
    "                # print('[{}] {}->{}: {:.3f}'.format(i, results[-1]['x_cols'], results[-1]['y_col'], results[-1]['mean_score']))\n",
    "                i += 1\n",
    "    results.sort(key=lambda x: x['mean_score'], reverse=True)\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(os.path.join(OUTPUT_PATH, 'regression.csv'))\n",
    "    display(df_results)\n",
    "                           \n",
    "# Input\n",
    "# df_movies - List of movie titles and various stats\n",
    "function6(df_movies) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 7 - Simple Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function 8 - Complex Classification\n",
    "\n",
    "I really want to classify something based on the bag of keywords associated with each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def function8(df_movies, df_movie_stats, df_stat_infos):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression \n",
    "    import statsmodels.formula.api as smf\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    def preprocessing1(df_movies, df_movie_stats, df_stat_infos):\n",
    "        def percentile(n):\n",
    "            def percentile_(x):\n",
    "                return np.percentile(x, n)\n",
    "            percentile_.__name__ = 'percentile_%s' % n\n",
    "            return percentile_\n",
    "\n",
    "        df_rate_of_return = df_movies[['imdb_id', 'rate_of_return_log_norm']]\n",
    "        df_rate_of_return = df_rate_of_return.dropna()\n",
    "        df_merged_stats_infos = pd.merge(left=df_movie_stats, right=df_stat_infos, on='col_idx', how='left')\n",
    "        df_merged_stats_infos = df_merged_stats_infos[df_merged_stats_infos['col'] == 'keywords'].drop(columns=['col'])\n",
    "        df_merged = pd.merge(left=df_rate_of_return, right=df_merged_stats_infos, on='imdb_id', how='left')\n",
    "        df_merged = df_merged.groupby(by=['col_idx', 'slug', 'pretty']).agg({'rate_of_return_log_norm': ['count', 'min', percentile(25), 'mean',  percentile(75), 'max',  'median', 'std']})\n",
    "        df_merged['count'] = df_merged[('rate_of_return_log_norm', 'count')]\n",
    "        df_merged.drop(columns=[('rate_of_return_log_norm', 'count')])\n",
    "        df_merged.sort_values(by='count', ascending=False, inplace=True)\n",
    "        df_merged.reset_index(inplace=True)\n",
    "        return df_merged\n",
    "    \n",
    "    # May not be necessary to limit rows\n",
    "    def preprocessing2(df):\n",
    "        ROWS_REMAINING_THRESHOLD = 250\n",
    "        i = 0\n",
    "        while df[df[('rate_of_return_log_norm', 'count')] > i].shape[0] >= ROWS_REMAINING_THRESHOLD:\n",
    "            i += 1\n",
    "        df = df[df[('rate_of_return_log_norm', 'count')] > i]\n",
    "        df[(df[('rate_of_return_log_norm', 'mean')] < 0)]\n",
    "        return df\n",
    "        \n",
    "    def preprocessing3(df_movies, df_movie_stats, df_rate_of_return_vs_keywords):\n",
    "        df_keywords = df_rate_of_return_vs_keywords[['col_idx', 'slug', 'pretty', 'count']]\n",
    "        df_keywords_vs_movies = pd.merge(left=df_movie_stats, right=df_keywords, on='col_idx', how='right')\n",
    "        df_keywords_vs_movies.rename(columns=''.join, inplace=True)\n",
    "        df = pd.get_dummies(df_keywords_vs_movies[['imdb_id', 'col_idx']], columns=['col_idx'], prefix='', prefix_sep='')#, sparse=True)\n",
    "        df = df.groupby(by='imdb_id').sum()\n",
    "        # Convert the dataframe to a sparse dataframe\n",
    "        dtype = pd.SparseDtype(int, fill_value=0)\n",
    "        df = df.astype(dtype)\n",
    "        return df\n",
    "    \n",
    "    def preprocessing4(df_movies, df_movies_preproc):\n",
    "        return pd.merge(left=df_movies[['imdb_id', 'class_performance', 'class_success']], right=df_movies_preproc, on='imdb_id', how='inner')\n",
    "    \n",
    "    def make_formula_str(x_cols, y_col):\n",
    "        if type(y_col) == list:\n",
    "            y_col = y_col[0]\n",
    "        formulaString = '{} ~ Q(\\\"{}\\\")'.format(y_col, x_cols[0])\n",
    "        for col in x_cols[1:]:\n",
    "            formulaString += ' + Q(\\\"{}\\\")'.format(col)\n",
    "        # print('Formula String = \\\"{}\\\"'.format(formulaString))\n",
    "        return formulaString\n",
    "    \n",
    "    \n",
    "    def calculate_r_squared(df):\n",
    "        df = df.sample(frac=1)\n",
    "        y_col_lst = ['class_performance', 'class_success']\n",
    "        X = df[df.columns.difference(['imdb_id', 'class_performance', 'class_success'])]\n",
    "        x_cols = X.columns\n",
    "        X = X.values\n",
    "        \n",
    "        for y_name in y_col_lst:\n",
    "            y = df[y_name].values\n",
    "            formString = make_formula_str(x_cols, y_name)\n",
    "            model = LogisticRegression(random_state=0, multi_class='ovr', solver = 'liblinear')\n",
    "\n",
    "            # 10-fold cross validation\n",
    "            kf = KFold(n_splits=10)\n",
    "            kf.get_n_splits(X)\n",
    "            scoresSK = list()\n",
    "            scores_St = list()\n",
    "\n",
    "            for train_idx, test_idx in kf.split(X):\n",
    "                X_train, X_test = X[train_idx], X[test_idx]\n",
    "                y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "                # using SK Learn\n",
    "                fit = model.fit(X_train, y_train)\n",
    "                scoresSK.append(fit.score(X_test, y_test))\n",
    "\n",
    "            yield np.mean(scoresSK), np.std(scoresSK)\n",
    "    \n",
    "    df_rate_of_return_vs_keywords = preprocessing1(df_movies, df_movie_stats, df_stat_infos)\n",
    "    df_rate_of_return_vs_keywords = preprocessing2(df_rate_of_return_vs_keywords)\n",
    "    df_movies_preproc = preprocessing3(df_movies, df_movie_stats, df_rate_of_return_vs_keywords)\n",
    "    df_movies_preproc = preprocessing4(df_movies, df_movies_preproc)\n",
    "    score1, score2 = calculate_r_squared(df_movies_preproc)\n",
    "    mean1, std_dev1 = score1\n",
    "    print(mean1)\n",
    "    mean2, std_dev2 = score2\n",
    "    print(mean2)\n",
    "\n",
    "# Input\n",
    "# df_movies - List of movie titles and various stats\n",
    "function8(df_movies, df_movie_stats, df_stat_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
